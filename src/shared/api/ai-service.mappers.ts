// import type { TablesInsert, TablesUpdate } from '@noggin/types/database.types'
// // Import the correct types from quiz-generation-types
// import type {
//   GeneratedQuiz,
//   GradedResponse,
//   GradedSubmission,
// } from '@noggin/types/ai/generated-quiz.types'
// import type { Question } from '@noggin/types/view/question.types' // For original question context
// import type { Submission } from '@noggin/types/view/submission.types' // For original submission context

// // Define input/output types for clarity, aligning with hook expectations
// type CreateQuizInput = Pick<TablesInsert<'quizzes'>, 'title' | 'time_limit_seconds'>
// type CreateQuestionInput = Omit<
//   TablesInsert<'questions'>,
//   'user_id' | 'id' | 'quiz_id' | 'updated_at'
// >
// type UpdateSubmissionInputData = Pick<
//   TablesUpdate<'submissions'>,
//   'grade_percent' | 'letter_grade' | 'status'
// >
// type UpdateResponseInputData = Pick<TablesUpdate<'responses'>, 'feedback' | 'is_correct'>

// // Type returned by mapGeneratedQuizToDbInputs
// export type MappedQuizDbInputs = {
//   quizInput: CreateQuizInput
//   questionsInput: CreateQuestionInput[]
// }

// // Type returned by mapAIGradingResultToDbUpdates
// export type MappedGradingDbUpdates = {
//   submissionUpdate: UpdateSubmissionInputData
//   responseUpdates: { responseId: string; updates: UpdateResponseInputData }[]
// }

// /**
//  * Maps the raw AI-generated quiz data to the input formats required by
//  * the createQuiz and createQuestions API mutation hooks.
//  *
//  * @param generatedQuiz - The raw quiz data generated by the AI service.
//  * @returns An object containing the quiz input and an array of question inputs.
//  */
// export function mapGeneratedQuizToDbInputs(generatedQuiz: GeneratedQuiz): MappedQuizDbInputs {
//   const quizInput: CreateQuizInput = {
//     title: generatedQuiz.title,
//     // time_limit_seconds: null, // Set default or handle elsewhere if needed
//   }

//   let sequence = 0
//   const mcQuestions = (generatedQuiz.multipleChoiceQuestions || []).map((q) => {
//     sequence++
//     return {
//       question_text: q.question,
//       question_type: q.questionType,
//       choices: JSON.stringify(q.choices.map((c) => c.text)), // Stringify choices
//       correct_answer_text: null, // AI doesn't reliably provide this
//       sequence_order: sequence,
//     }
//   })

//   const writtenQuestions = (generatedQuiz.writtenQuestions || []).map((q) => {
//     sequence++
//     return {
//       question_text: q.question,
//       question_type: q.questionType,
//       choices: null,
//       correct_answer_text: null, // AI doesn't reliably provide this
//       sequence_order: sequence,
//     }
//   })

//   const questionsInput: CreateQuestionInput[] = [...mcQuestions, ...writtenQuestions]

//   return { quizInput, questionsInput }
// }

// /**
//  * Maps the raw AI grading result to the input formats required by
//  * the updateSubmission and updateResponse API mutation hooks.
//  * Matches AI responses to original responses using question text.
//  *
//  * @param aiResult - The raw grading data returned by the AI service (type GradedSubmission from quiz-generation-types).
//  * @param originalSubmission - The original Submission object (View Type) containing original responses with IDs.
//  * @param questions - The array of original questions (Question View Type).
//  * @returns An object containing updates for the submission and an array of updates for individual responses.
//  */
// export function mapAIGradingResultToDbUpdates(
//   aiResult: GradedSubmission, // Use the correct imported type for the raw AI result
//   originalSubmission: Submission,
//   questions: Question[] // Use Question View Type
// ): MappedGradingDbUpdates {
//   // Calculate totalScore based on the length of the responses array from AI result
//   // Assuming totalScore represents the count of correct answers if not explicitly provided by AI schema
//   const totalScore = aiResult.responses.reduce((sum, r) => sum + (r.isCorrect ? 1 : 0), 0)
//   const totalQuestions = questions.length
//   const gradePercent = totalQuestions > 0 ? Math.round((totalScore / totalQuestions) * 100) : null

//   // Basic letter grade calculation (adjust thresholds as needed)
//   let letterGrade: string | null = null
//   if (gradePercent !== null) {
//     if (gradePercent >= 90) letterGrade = 'A'
//     else if (gradePercent >= 80) letterGrade = 'B'
//     else if (gradePercent >= 70) letterGrade = 'C'
//     else if (gradePercent >= 60) letterGrade = 'D'
//     else letterGrade = 'F'
//   }

//   const submissionUpdate: UpdateSubmissionInputData = {
//     status: 'graded',
//     grade_percent: gradePercent,
//     letter_grade: letterGrade,
//     // overallFeedback from aiResult is not stored on the submission table
//   }

//   const responseUpdates: { responseId: string; updates: UpdateResponseInputData }[] = []

//   aiResult.responses.forEach((aiResponse: GradedResponse) => {
//     // Use correct GradedResponse type
//     // Find original question based on text match
//     const originalQuestion = questions.find((q) => q.questionText === aiResponse.question)
//     if (!originalQuestion) {
//       console.warn(
//         `Could not find original question matching AI graded question text: "${aiResponse.question}". Skipping response update.`
//       )
//       return
//     }

//     // Find original response using the matched question's ID
//     const originalResponse = originalSubmission.responses.find(
//       (r) => r.questionId === originalQuestion.id
//     )
//     if (!originalResponse) {
//       console.warn(
//         `Could not find original response for question ID: "${originalQuestion.id}". Skipping response update.`
//       )
//       return
//     }

//     responseUpdates.push({
//       responseId: originalResponse.id,
//       updates: {
//         feedback: aiResponse.feedback,
//         is_correct: aiResponse.isCorrect,
//       },
//     })
//   })

//   return { submissionUpdate, responseUpdates }
// }
